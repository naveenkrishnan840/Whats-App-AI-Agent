# What's App AI Agent

<div align="center">
  <!-- Backend -->
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" />
  <img src="https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white" />
  <img src="https://img.shields.io/badge/SQLite-003B57?style=for-the-badge&logo=sqlite&logoColor=white" />
  <img src="https://img.shields.io/badge/Qdrant-FF6F00?style=for-the-badge&logo=qdrant&logoColor=white" />
  <img src="https://img.shields.io/badge/Groq-FF4A00?style=for-the-badge&logo=groq&logoColor=white" />
  <img src="https://img.shields.io/badge/LangChain-121212?style=for-the-badge&logo=chainlink&logoColor=white" />
  <img src="https://img.shields.io/badge/LangGraph-FF6B6B?style=for-the-badge&logo=graph&logoColor=white" />
  <img src="https://img.shields.io/badge/OpenAI_Whisper-412991?style=for-the-badge&logo=openai&logoColor=white" />
  <img src="https://img.shields.io/badge/ElevenLabs-000000?style=for-the-badge&logo=elevenlabs&logoColor=white" />
  <img src="https://img.shields.io/badge/Together.AI-FF5733?style=for-the-badge&logo=togetherai&logoColor=white" />
  <img src="https://img.shields.io/badge/LLaMA_Text_Model-1877F2?style=for-the-badge&logo=meta&logoColor=white" />
  <img src="https://img.shields.io/badge/LLaMA_Vision_Model-1877F2?style=for-the-badge&logo=meta&logoColor=white" />
  <img src="https://img.shields.io/badge/Gemma_Model-4285F4?style=for-the-badge&logo=google&logoColor=white" />

  <!-- Frontend -->
  <img src="https://img.shields.io/badge/JavaScript-F7DF1E?style=for-the-badge&logo=javascript&logoColor=black" />
  <img src="https://img.shields.io/badge/Tailwind_CSS-38B2AC?style=for-the-badge&logo=tailwind-css&logoColor=white" />
  <img src="https://img.shields.io/badge/React-61DAFB?style=for-the-badge&logo=react&logoColor=black" />

  <h3>Your Ava's Co-pilot for What's App AI agents Chat Bot ğŸš€</h3>

  <p align="center">
    <b> Memory Extraction Agent | Memory Injection Agent | Workflow Router Agent | Audio Agent | Image Agent | Summarize Conversation Agent </b>
  </p>
</div>

# Overview
<b>Avaâ€™s Bot</b> is a smart, multi-agent system designed to provide a seamless, efficient, and personalized experience for users interacting via WhatsApp. With the ability to handle text, images, and audio, Avaâ€™s Bot leverages AI-powered NLP, memory management to deliver context-aware, human-like conversations.

By integrating SQLite for short-term memory, Qdrant for long-term memory, and real-time workflow automation, Avaâ€™s Bot ensures intelligent decision-making while enhancing user interactions. The bot can process text-to-text, text-to-image, image-to-text, text-to-audio, and audio-to-text requests, making it a powerful tool for advanced conversational AI applications.

By leveraging cutting-edge AI models, Avaâ€™s Bot streamlines complex interactions, making AI-driven conversations smarter, more interactive, and highly personalized. ğŸš€

# Motivation
Efficiency meets innovation. With the power of intelligent AI, Avaâ€™s Bot redefines seamless and personalized conversations. It doesnâ€™t just process text, images, and audioâ€”it enhances interactions, making them more intuitive, context-aware, and engaging.

Whether itâ€™s understanding speech, generating images, or recalling past conversations, Avaâ€™s Bot is your intelligent companion, streamlining complex interactions with effortless precision. With cutting-edge memory integration and AI capabilities, it ensures every conversation is smarter, more interactive, and deeply personalized.

Embrace the future of AI-driven conversations and experience the next evolution of intelligent assistance. ğŸš€

## Agents Features & Agent Types & Agent Informations

## Agent Capabilities
  ### 1. Memory Extraction
  The Memory Extraction is used to store chat information for both ava's and user chat to get seemless experiences.
#### Capabilities:
  - **Understanding Context** â€“ Extracts key details from user conversations to maintain contextual awareness.
  - **Long-Term Memory** â€“ Utilizes Qdrant (vector database) to store current conversations and enhance personalized interactions over time.
  - **Intelligent Prioritization** â€“ Identifies and classifies important information, ensuring relevant memories are stored while filtering out unnecessary data.
  - **Efficient Retrieval** â€“ Enables Avaâ€™s Bot to remember user preferences, past queries, and ongoing tasks, leading to smoother, more natural conversations.
  - **Multi-Modal Memory Processing** â€“ Extracts meaningful insights from text, images, and audio, allowing Avaâ€™s Bot to recall and reference past interactions across different formats.

### 2. Memory Injection
  The Flights Assistant is responsible for assisting users with flight bookings, availability checks, and flight-related queries.

#### Capabilities:
  - **Context-Aware Responses** â€“ Retrieves relevant past conversations from SQLite (short-term memory) or Qdrant (long-term memory) to provide seamless, intelligent replies.
  - **Personalized Interactions** â€“ Injects stored knowledge into conversations, ensuring Avaâ€™s Bot remembers user preferences, past questions, and important details.
  - **Multi-Modal Integration** â€“ Injects relevant text, image, and audio-based memory, allowing natural continuity across different conversation formats.
  - **Dynamic Memory Retrieval** â€“ Uses AI-driven logic to decide when and what memory should be injected, preventing unnecessary or outdated responses.
  - **Enhancing User Experience** â€“ Eliminates repetitive questioning by recalling past interactions, making conversations fluid and engaging.
  - **Workflow Optimization** â€“ Works alongside the Memory Extraction and Workflow Decision agents to ensure the right information is used at the right time.
  - **Adaptive Learning** â€“ Continuously updates and refines memory based on new user inputs, improving response accuracy over time.
  - **Efficient Query Processing** â€“ Uses vector search (Qdrant) to find the most relevant stored memories and integ
    
### 3. Workflow Router
  The workflow router is a decision-making system determines whether to process text, images, or audio. The system dynamically executes the right AI model for the given input.

#### Capabilities:
  - **Task Decision Engine** â€“ Determines whether the input is text, image, or audio and routes it to the appropriate processing pipeline.
  - **Seamless Multi-Modal Handling** â€“ Directs text queries to NLP models, images to vision models, and audio to speech processing for efficient execution.
  - **Real-Time Processing** â€“ Ensures low-latency routing, making decisions instantly to provide quick responses.
  - **Memory Integration** â€“ Works alongside Memory Extraction & Injection to enhance responses with stored knowledge.
  - **Memory Integration** â€“ Works alongside Memory Extraction & Injection to enhance responses with stored knowledge.
    
### 4. Audio Agent
  The audio agent is used to interact with elevanlabs to get model response to ava's voice as seemless experience. 

#### Capabilities:
  - **Text-to-Speech Generation** â€“ Uses **ElevenLabs.io** to generate realistic, human-like audio responses.
  - **English-Language Support** â€“ Enables Avaâ€™s Bot to understand and respond in multiple languages, making interactions more accessible.
  - **Seamless Workflow Integration** â€“ Works with the Workflow Router to determine when to process audio inputs or generate speech responses.
  - **Noise Reduction & Optimization** â€“ Ensures clean and high-quality audio processing, even in noisy environments.
    
### 5. Conversation
  Uses LLaMA, Gemma, and other LLMs to generate high-quality, human-like text responses.

#### Capabilities:
  - **Advanced NLP Processing** â€“ Uses LLaMA, Gemma, and other LLMs to generate high-quality, human-like text responses.
  - **Context-Aware Responses** â€“ Leverages Memory Extraction & Injection via Qdrant to maintain conversational flow and recall past interactions.
  - **Multi-Turn Dialogue Handling** â€“ Supports long-form conversations, allowing seamless, intelligent discussions over multiple messages.

### 6. summarize conversation 
  This agents is used to summarize the previous memory and feed into model to get appropriate response.
  
### Agent Architecture Diagrams

#### Deep multi Agent Work Flow
<img src="https://github.com/naveenkrishnan840/Whats-App-AI-Agent/blob/main/backend/graph.png"/>

## Project Structure 
```
whats-app-AI-Agent/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ src/
|   |    â”œâ”€â”€ core                          # Agent definitions and workflow
|   |    |    |â”€â”€â”€â”€â”€â”€ prompt.py
|   |    |    |â”€â”€â”€â”€â”€â”€ schedules.py
|   |    â”œâ”€â”€ edges
|   |    |    |â”€â”€â”€â”€â”€â”€  edges.py
|   |    â”œâ”€â”€ modules
|   |    |    |â”€â”€â”€ image
|   |    |    |      |â”€â”€â”€ image_to_text.py
|   |    |    |      |â”€â”€â”€ text_to_image.py
|   |    |    |â”€â”€â”€ memory
|   |    |    |      |â”€â”€â”€ long term
|   |    |    |      |     |â”€â”€â”€ memory_manager.py
|   |    |    |      |     |â”€â”€â”€ vector_store.py
|   |    |    |      |â”€â”€â”€ schedules
|   |    |    |      |     |â”€â”€â”€ context_generation.py
|   |    |    |      |â”€â”€â”€ speechs
|   |    |    |      |     |â”€â”€â”€ speech_to_text.py
|   |    |    |      |     |â”€â”€â”€ text_to_speech.py
|   |    |â”€â”€â”€ nodes
|   |    |    |â”€â”€â”€ __init__.py
|   |    |    |â”€â”€â”€ audio_node.py
|   |    |    |â”€â”€â”€ context_injection_node.py
|   |    |    |â”€â”€â”€ coversation_node.py
|   |    |    |â”€â”€â”€ image_node.py
|   |    |    |â”€â”€â”€ memory_extraction_node.py
|   |    |    |â”€â”€â”€ memory_injection_node.py
|   |    |    |â”€â”€â”€ router_ndoe.py
|   |    |    |â”€â”€â”€ summarize_conversion_ndoe.py
|   |    |â”€â”€â”€ utils
|   |    |    |â”€â”€â”€ chains.py
|   |â”€â”€â”€ create_table.py
|   |â”€â”€â”€ main.py # Main entry point
|   |â”€â”€â”€ pyproject.toml # create virtual env using poetry   

```

## Setup Instructions

### Backend Setup

1. Clone the repository
   ```bash
   git clone https://github.com/naveenkrishnan840/Whats-App-AI-Agent.git
   cd Whats-App-AI-Agent
   cd backend
   ```

2. Install Poetry (if not already installed)

   Mac/Linux:
   ```bash
   curl -sSL https://install.python-poetry.org | python3 -
   ```
   Windows:
   ```bash
   (Invoke-WebRequest -Uri https://install.python-poetry.org -UseBasicParsing).Content | python -
   ```

3. Set Python version for Poetry
   ```bash
   poetry env use python3.12
   ```

4. Activate the Poetry shell:
   For Unix/Linux/MacOS:
   ```bash
   poetry shell
   # or manually
   source $(poetry env info --path)/bin/activate
   ```
   For Windows:
   ```bash
   poetry shell
   # or manually
   & (poetry env info --path)\Scripts\activate
   ```

5. Install dependencies using Poetry:
   ```bash
   poetry install
   ```

6. Set up environment variables in `.env`:
   ```bash
   GROQ_API_KEY=Your Api key
   ELEVENLABS_API_KEY=Your Api key
   ELEVENLABS_VOICE_ID=voice Id
   TOGETHER_API_KEY=Your Api key
   QDRANT_API_KEY=Your Api key
   QDRANT_URL=Your Url
   QDRANT_PORT=6333
   TEXT_MODEL_NAME=llama-3.3-70b-versatile
   SMALL_TEXT_MODEL_NAME=gemma2-9b-it
   STT_MODEL_NAME=whisper-large-v3-turbo
   TTS_MODEL_NAME=eleven_flash_v2_5
   TTI_MODEL_NAME=black-forest-labs/FLUX.1-schnell-Free
   ITT_MODEL_NAME=llama-3.2-90b-vision-preview
   MEMORY_TOP_K=5
   ROUTER_MESSAGES_TO_ANALYZE=5
   TOTAL_MESSAGES_SUMMARY_TRIGGER=20
   TOTAL_MESSAGES_AFTER_SUMMARY=5
   SHORT_TERM_MEMORY_DB_PATH=your sqlite db path

   ```

7. Run the backend:

   Make sure you are in the backend folder

    ```bash
    uvicorn app.main:app --reload --port 8000 
    ```

   For Windows User:

    ```bash
    uvicorn app.main:app --port 8000
    ```

8. Access the API at `http://localhost:8000`

### Frontend Setup

1. Open a new terminal and make sure you are in the WebRover folder:
   ```bash
   cd frontend
   ```

2. Install dependencies:
   ```bash
   npm install
   ```

3. Run the frontend:
   ```bash
   npm run dev
   ```

4. Access the frontend at `http://localhost:3000`

For mac users: 

Try running http://localhost:3000 on Safari browser. 

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

Made with â¤ï¸ by [@naveenkrishnan840](https://github.com/naveenkrishnan840)
